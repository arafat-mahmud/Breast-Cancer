{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66cbcd91",
   "metadata": {},
   "source": [
    "# üè• Enhanced CVFBJTL-BCD: Breast Cancer Diagnosis on Kaggle\n",
    "\n",
    "## Computer Vision with Fusion Based Joint Transfer Learning\n",
    "\n",
    "**Target Performance:** >98.18% accuracy (paper baseline)\n",
    "\n",
    "**GPU:** Tesla P100 / T4 (enable in Settings ‚Üí Accelerator ‚Üí GPU)\n",
    "\n",
    "---\n",
    "\n",
    "### üìã Features:\n",
    "- ‚úÖ Gabor Filtering for noise reduction\n",
    "- ‚úÖ DenseNet201 + InceptionV3 + MobileNetV2 fusion\n",
    "- ‚ú® **Vision Transformer (NOVELTY)**\n",
    "- ‚úÖ Stacked Autoencoder (SAE)\n",
    "- ‚úÖ SMOTE for dataset balancing\n",
    "- üîç Grad-CAM explainability\n",
    "- üìä Comprehensive evaluation\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ Quick Start:\n",
    "1. Enable GPU (Settings ‚Üí Accelerator ‚Üí GPU T4 x2)\n",
    "2. Add BreaKHis dataset to input\n",
    "3. Run all cells\n",
    "4. Download outputs from `/kaggle/working/outputs/`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbef0eb",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b5d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Python version\n",
    "import sys\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"Python Executable: {sys.executable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d05f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional packages if needed\n",
    "# Kaggle has most packages pre-installed\n",
    "!pip install --quiet imbalanced-learn albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429894b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {keras.__version__}\")\n",
    "print(f\"NumPy Version: {np.__version__}\")\n",
    "\n",
    "# Check GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"\\n‚úÖ GPU Available: {len(gpus)} GPU(s)\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"   {gpu}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No GPU found! Enable GPU: Settings ‚Üí Accelerator ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be52860e",
   "metadata": {},
   "source": [
    "## üìÅ Step 2: Verify Dataset\n",
    "\n",
    "**Important:** You need to upload the BreaKHis dataset to Kaggle:\n",
    "\n",
    "1. Go to https://www.kaggle.com/datasets\n",
    "2. Click \"New Dataset\"\n",
    "3. Upload your BreaKHis_v1 folder\n",
    "4. Add the dataset to this notebook (Add Data button)\n",
    "\n",
    "Expected structure:\n",
    "```\n",
    "/kaggle/input/breakhis-dataset/\n",
    "‚îú‚îÄ‚îÄ benign/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ SOB/\n",
    "‚îî‚îÄ‚îÄ malignant/\n",
    "    ‚îî‚îÄ‚îÄ SOB/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefcba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all available datasets in Kaggle input\n",
    "print(\"üìÇ Available Kaggle Input Datasets:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if os.path.exists('/kaggle/input'):\n",
    "    for item in os.listdir('/kaggle/input'):\n",
    "        path = os.path.join('/kaggle/input', item)\n",
    "        if os.path.isdir(path):\n",
    "            print(f\"\\nüìÅ {item}/\")\n",
    "            # Show first level contents\n",
    "            for sub in os.listdir(path)[:5]:\n",
    "                print(f\"   ‚îî‚îÄ‚îÄ {sub}\")\n",
    "else:\n",
    "    print(\"Not running on Kaggle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866f6cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify BreaKHis dataset structure\n",
    "# MODIFY THIS PATH if your dataset is named differently\n",
    "DATASET_PATH = '/kaggle/input/breakhis-dataset'  # Change this if needed\n",
    "\n",
    "print(f\"Checking dataset at: {DATASET_PATH}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if os.path.exists(DATASET_PATH):\n",
    "    print(\"‚úÖ Dataset found!\")\n",
    "    \n",
    "    # Count images\n",
    "    total_images = 0\n",
    "    for root, dirs, files in os.walk(DATASET_PATH):\n",
    "        total_images += len([f for f in files if f.endswith('.png')])\n",
    "    \n",
    "    print(f\"\\nüìä Total images: {total_images}\")\n",
    "    print(\"\\nüìÅ Directory structure:\")\n",
    "    \n",
    "    for root, dirs, files in os.walk(DATASET_PATH):\n",
    "        level = root.replace(DATASET_PATH, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        if level < 3:  # Limit depth\n",
    "            subindent = ' ' * 2 * (level + 1)\n",
    "            for d in dirs[:3]:\n",
    "                print(f\"{subindent}‚îú‚îÄ‚îÄ {d}/\")\n",
    "else:\n",
    "    print(\"‚ùå Dataset not found!\")\n",
    "    print(\"\\nüì• Please upload BreaKHis dataset:\")\n",
    "    print(\"   1. Click 'Add Data' button on the right\")\n",
    "    print(\"   2. Upload your dataset\")\n",
    "    print(\"   3. Restart kernel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd3695",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Step 3: Upload Project Files\n",
    "\n",
    "You need to upload these Python files to Kaggle:\n",
    "\n",
    "**Required files:**\n",
    "1. `enhanced_cvfbjtl_bcd_model.py`\n",
    "2. `breakhis_dataloader.py`\n",
    "3. `advanced_explainability.py` (or `gradcam_explainability.py`)\n",
    "\n",
    "**How to upload:**\n",
    "- Method 1: Use \"File\" ‚Üí \"Upload Notebook or Script\"\n",
    "- Method 2: Copy files into cells below and save as .py files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cca917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if required files are present\n",
    "required_files = [\n",
    "    'enhanced_cvfbjtl_bcd_model.py',\n",
    "    'breakhis_dataloader.py',\n",
    "    'advanced_explainability.py'\n",
    "]\n",
    "\n",
    "print(\"Checking required files:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "all_present = True\n",
    "for file in required_files:\n",
    "    if os.path.exists(file):\n",
    "        print(f\"‚úÖ {file}\")\n",
    "    else:\n",
    "        print(f\"‚ùå {file} - NOT FOUND\")\n",
    "        all_present = False\n",
    "\n",
    "if all_present:\n",
    "    print(\"\\n‚úÖ All required files present!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Some files are missing. Please upload them.\")\n",
    "    print(\"\\nüì§ Upload instructions:\")\n",
    "    print(\"   1. Click 'Add Data' ‚Üí 'Upload'\")\n",
    "    print(\"   2. Upload the Python files from your project\")\n",
    "    print(\"   3. Restart kernel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2037f1",
   "metadata": {},
   "source": [
    "## üöÄ Step 4: Run Training\n",
    "\n",
    "This will:\n",
    "1. Configure GPU for optimal performance\n",
    "2. Load and preprocess BreaKHis dataset\n",
    "3. Build Enhanced CVFBJTL-BCD model\n",
    "4. Train for 50 epochs (with early stopping)\n",
    "5. Evaluate on test set\n",
    "6. Generate plots and Grad-CAM visualizations\n",
    "7. Save all outputs to `/kaggle/working/outputs/`\n",
    "\n",
    "**Expected time:** ~45-60 minutes on Tesla P100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e98ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the complete training pipeline\n",
    "# This uses kaggle_train_cvfbjtl_bcd.py\n",
    "\n",
    "# If you haven't uploaded the training script, you can run it inline:\n",
    "%run kaggle_train_cvfbjtl_bcd.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2baae75",
   "metadata": {},
   "source": [
    "## üìä Step 5: View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ffa1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display results\n",
    "import json\n",
    "\n",
    "results_path = '/kaggle/working/outputs/results.json'\n",
    "\n",
    "if os.path.exists(results_path):\n",
    "    with open(results_path, 'r') as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "    print(\"üéØ FINAL RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Test Accuracy:  {results['test_accuracy']*100:.2f}%\")\n",
    "    print(f\"Test Precision: {results['test_precision']*100:.2f}%\")\n",
    "    print(f\"Test Recall:    {results['test_recall']*100:.2f}%\")\n",
    "    print(f\"Test F1-Score:  {results['test_f1']*100:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nüìà COMPARISON WITH PAPER:\")\n",
    "    print(f\"Paper:          {results['paper_accuracy']}%\")\n",
    "    print(f\"Our Model:      {results['test_accuracy']*100:.2f}%\")\n",
    "    print(f\"Improvement:    {results['improvement']:+.2f}%\")\n",
    "    \n",
    "    if results['improvement'] > 0:\n",
    "        print(\"\\nüéâ BETTER THAN PAPER! ‚ú®\")\n",
    "else:\n",
    "    print(\"Results not found. Training may not have completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ba64db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training plots\n",
    "from IPython.display import Image, display\n",
    "\n",
    "plots = [\n",
    "    'training_history.png',\n",
    "    'confusion_matrix.png',\n",
    "    'roc_curve.png'\n",
    "]\n",
    "\n",
    "for plot in plots:\n",
    "    plot_path = f'/kaggle/working/outputs/plots/{plot}'\n",
    "    if os.path.exists(plot_path):\n",
    "        print(f\"\\nüìä {plot}:\")\n",
    "        display(Image(filename=plot_path))\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  {plot} not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e8a0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some Grad-CAM examples\n",
    "gradcam_dir = '/kaggle/working/outputs/plots/gradcam'\n",
    "\n",
    "if os.path.exists(gradcam_dir):\n",
    "    gradcam_files = sorted([f for f in os.listdir(gradcam_dir) if f.endswith('.png')])[:5]\n",
    "    \n",
    "    print(\"üîç GRAD-CAM VISUALIZATIONS (Sample):\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for gradcam_file in gradcam_files:\n",
    "        print(f\"\\n{gradcam_file}:\")\n",
    "        display(Image(filename=os.path.join(gradcam_dir, gradcam_file)))\n",
    "else:\n",
    "    print(\"No Grad-CAM visualizations found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e89a01",
   "metadata": {},
   "source": [
    "## üì• Step 6: Download Outputs\n",
    "\n",
    "All outputs are saved in `/kaggle/working/outputs/`\n",
    "\n",
    "**Files to download:**\n",
    "- `models/best_model.h5` - Trained model\n",
    "- `results.json` - Evaluation metrics\n",
    "- `TRAINING_REPORT.txt` - Complete report\n",
    "- `plots/*.png` - All visualizations\n",
    "- `logs/training_log.csv` - Training history\n",
    "\n",
    "**How to download:**\n",
    "1. Click \"Save Version\" to commit outputs\n",
    "2. Go to \"Output\" tab\n",
    "3. Download the entire `outputs` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61752b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all generated files\n",
    "output_dir = '/kaggle/working/outputs'\n",
    "\n",
    "if os.path.exists(output_dir):\n",
    "    print(\"üìÅ GENERATED FILES:\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for root, dirs, files in os.walk(output_dir):\n",
    "        level = root.replace(output_dir, '').count(os.sep)\n",
    "        indent = '  ' * level\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = '  ' * (level + 1)\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_size = os.path.getsize(file_path) / 1024  # KB\n",
    "            print(f\"{subindent}‚îú‚îÄ‚îÄ {file} ({file_size:.1f} KB)\")\n",
    "    \n",
    "    print(\"\\n‚úÖ All files ready for download!\")\n",
    "else:\n",
    "    print(\"Output directory not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06df24a",
   "metadata": {},
   "source": [
    "## üéì Step 7: Advanced Analysis (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34749712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model for further analysis\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_path = '/kaggle/working/outputs/models/best_model.h5'\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(\"Loading trained model...\")\n",
    "    model = load_model(model_path)\n",
    "    print(\"‚úÖ Model loaded successfully!\")\n",
    "    \n",
    "    # Model summary\n",
    "    print(\"\\nüìã Model Summary:\")\n",
    "    model.summary()\n",
    "else:\n",
    "    print(\"Model file not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b73f961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform additional analysis on test set\n",
    "# This cell is optional - for detailed analysis\n",
    "\n",
    "# Load test data (you'll need to modify this based on your data)\n",
    "# Example:\n",
    "# from breakhis_dataloader import BreaKHisDataLoader\n",
    "# loader = BreaKHisDataLoader(DATASET_PATH)\n",
    "# X_test, y_test, _ = loader.load_dataset(...)\n",
    "# predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c9df99",
   "metadata": {},
   "source": [
    "## üìù Summary\n",
    "\n",
    "### Training Complete! üéâ\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "1. **Download all outputs** from `/kaggle/working/outputs/`\n",
    "2. **Review the training report** for detailed metrics\n",
    "3. **Use the trained model** for predictions\n",
    "4. **Include results** in your research paper\n",
    "\n",
    "**For Research Paper:**\n",
    "- Accuracy, Precision, Recall, F1-Score metrics ‚úì\n",
    "- Confusion matrix visualization ‚úì\n",
    "- ROC curve and AUC ‚úì\n",
    "- Training/validation curves ‚úì\n",
    "- Grad-CAM explanations ‚úì\n",
    "- Comparison with baseline paper ‚úì\n",
    "\n",
    "**Publication Ready!** üìÑ\n",
    "\n",
    "---\n",
    "\n",
    "### üìß Support\n",
    "\n",
    "If you encounter any issues:\n",
    "1. Check GPU is enabled\n",
    "2. Verify dataset path is correct\n",
    "3. Ensure all Python files are uploaded\n",
    "4. Check the training logs for errors\n",
    "\n",
    "### üåü Citation\n",
    "\n",
    "If you use this code, please cite the original paper:\n",
    "\n",
    "```\n",
    "Iniyan et al. (2024). \"Enhanced breast cancer diagnosis through integration \n",
    "of computer vision with fusion based joint transfer learning using multi \n",
    "modality medical images.\" Scientific Reports, 14:28376.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Good luck with your research! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
